# Step 3: Assessment Engine v1 - Implementation Plan

**Objective**: Deliver a deterministic, auditable compliance assessment engine that computes scores, identifies gaps, and generates actionable recommendations based on questionnaire responses.

**Constraints**:
- 100% deterministic (no AI, no external API calls)
- Jurisdiction-aware (UAE/KSA/Qatar)
- Listing-aware (listed/non-listed)
- Based solely on question bank metadata (weights, pillars, applicability, answer types)
- Stable, auditable, and explainable outputs
- Free tier: Assessment results visible to all users
- Paid tier: Disclosure document generation (boundary spec required)

---

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Questionnaire Responses                       â”‚
â”‚              (QuestionAnswer[] + CompanyProfile)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      SCORING MODULE                              â”‚
â”‚  src/lib/scoring/                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ compute-scores.ts                                          â”‚ â”‚
â”‚  â”‚ â€¢ Per-pillar scores (0-100)                                â”‚ â”‚
â”‚  â”‚ â€¢ Overall weighted score                                   â”‚ â”‚
â”‚  â”‚ â€¢ Weighted normalization                                   â”‚ â”‚
â”‚  â”‚ â€¢ Answer type-specific scoring rules                       â”‚ â”‚
â”‚  â”‚ â€¢ Exclude conditional questions not shown                  â”‚ â”‚
â”‚  â”‚ â€¢ Handle unanswered/N/A                                    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GAP DETECTION MODULE                          â”‚
â”‚  src/lib/gaps/                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ detect-gaps.ts                                             â”‚ â”‚
â”‚  â”‚ â€¢ Identify missing/suboptimal answers                      â”‚ â”‚
â”‚  â”‚ â€¢ Severity: critical/high/medium/low                       â”‚ â”‚
â”‚  â”‚ â€¢ Derived from: weight + answer state + criticality        â”‚ â”‚
â”‚  â”‚ â€¢ Rationale + required_action + evidence_needed            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              RECOMMENDATION GENERATION MODULE                    â”‚
â”‚  src/lib/recommendations/                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ generate-recommendations.ts                                â”‚ â”‚
â”‚  â”‚ â€¢ Deterministic gap â†’ recommendation mapping               â”‚ â”‚
â”‚  â”‚ â€¢ Maintained mapping table in src/data/recommendations/    â”‚ â”‚
â”‚  â”‚ â€¢ Effort/impact estimates                                  â”‚ â”‚
â”‚  â”‚ â€¢ "Why it matters" explanations                            â”‚ â”‚
â”‚  â”‚ â€¢ Jurisdiction-aware where relevant                        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  ASSESSMENT ORCHESTRATOR                         â”‚
â”‚  src/lib/assessment/                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ run-assessment.ts                                          â”‚ â”‚
â”‚  â”‚ â€¢ Orchestrates scoring â†’ gaps â†’ recommendations            â”‚ â”‚
â”‚  â”‚ â€¢ Builds explanation object                                â”‚ â”‚
â”‚  â”‚ â€¢ Returns AssessmentResult                                 â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  PERSISTENCE LAYER                               â”‚
â”‚  src/hooks/use-assessment-results.ts                             â”‚
â”‚  â€¢ React Query hooks for save/load                              â”‚
â”‚  â€¢ Uses existing assessment_results table                       â”‚
â”‚  â€¢ No migration needed (schema already exists)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       UI LAYER                                   â”‚
â”‚  src/pages/ComplianceResults.tsx (new route)                     â”‚
â”‚  src/components/assessment/                                      â”‚
â”‚  â€¢ ScoreCard.tsx - Overall + pillar scores                      â”‚
â”‚  â€¢ GapsList.tsx - Top gaps with severity                        â”‚
â”‚  â€¢ RecommendationsList.tsx - Actionable items                   â”‚
â”‚  â€¢ MethodologyPanel.tsx - "Explain methodology"                 â”‚
â”‚  â€¢ UpgradePrompt.tsx - Locked disclosure feature               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Data Flow

1. **Input**: `QuestionnaireResponse` + `QuestionnaireTemplate` + `CompanyProfile`
2. **Scoring**: Compute per-pillar and overall scores using weighted normalization
3. **Gap Detection**: Identify gaps based on low scores, missing answers, critical questions
4. **Recommendation Generation**: Map gaps to actionable recommendations via lookup table
5. **Persistence**: Save `AssessmentResult` to Supabase
6. **Display**: Render results in UI with methodology explanation
7. **Boundary**: Show locked "Generate Disclosure" button for paid tier

---

## Scoring Methodology

### Answer Type-Specific Scoring Rules

#### Boolean Questions
- `true` (affirmative): **100 points** (full compliance)
- `false` (negative): **0 points** (gap identified)
- Unanswered: **0 points** (gap identified)

#### Single Choice Questions
- Each option has a `score` field (0-100) added to question bank
- Awarded score = selected option's score
- Unanswered: **0 points**

#### Multiple Choice Questions
- Each selected option contributes proportionally
- Score = (sum of selected option scores) / (sum of all option scores) Ã— 100
- Unanswered: **0 points**

#### Number Questions
- Define `min`, `max`, `target` in question metadata
- Score = clamp((value - min) / (target - min) Ã— 100, 0, 100)
- Example: "How many independent directors?" - min=0, target=3, max=15
- Unanswered: **0 points**

#### Percentage Questions
- Direct mapping: value = score (0-100)
- Example: "What percentage of board is independent?" - 40% â†’ 40 points
- Unanswered: **0 points**

#### Text Questions
- Presence check only
- Non-empty text: **100 points** (disclosure provided)
- Empty/unanswered: **0 points** (gap)

#### Date Questions
- Recency check
- Define `max_age_months` in metadata
- If within max_age: **100 points**
- If older: scale linearly down to **50 points** at 2Ã— max_age
- If beyond 2Ã— max_age: **0 points**
- Unanswered: **0 points**

### Pillar Score Calculation

For each pillar (governance, esg, risk_controls, transparency):

```
pillar_score = Î£(question_score Ã— question_weight) / Î£(question_weight)
```

Where:
- Only applicable questions (jurisdiction + listing status) are included
- Only visible questions (conditional logic passes) are included
- Unanswered questions score 0 but contribute to denominator

### Overall Score Calculation

```
overall_score = Î£(pillar_score Ã— pillar_weight) / Î£(pillar_weight)
```

Pillar weights (configurable):
- Governance: **30%**
- ESG: **25%**
- Risk & Controls: **25%**
- Transparency: **20%**

---

## Gap Detection Methodology

### Severity Assignment (Deterministic)

```typescript
function determineSeverity(
  question: Question,
  answer: QuestionAnswer | undefined,
  score: number
): 'critical' | 'high' | 'medium' | 'low' {
  // Step 1: Check criticality metadata (new field added to question bank)
  if (question.criticality === 'critical' && score < 50) {
    return 'critical';
  }

  // Step 2: Check weight + score combination
  if (question.weight >= 8 && score === 0) {
    return 'critical'; // High-weight question completely unaddressed
  }

  if (question.weight >= 6 && score < 30) {
    return 'high';
  }

  if (question.weight >= 4 && score < 50) {
    return 'medium';
  }

  // Step 3: Low severity for minor gaps
  if (score < 70) {
    return 'low';
  }

  // No gap if score >= 70
  return null;
}
```

### Gap Structure

```typescript
interface Gap {
  id: string; // Generated UUID
  pillar: QuestionPillar;
  question_id: string;
  question_code: string;
  question_text: string;
  question_text_arabic?: string;
  severity: 'critical' | 'high' | 'medium' | 'low';
  current_score: number; // 0-100
  rationale: string; // Auto-generated based on severity + answer state
  required_action: string; // Derived from question type + expected answer
  evidence_needed: string[]; // From question.evidenceHint
}
```

### Rationale Generation (Deterministic)

```typescript
function generateRationale(question: Question, answer: QuestionAnswer | undefined, score: number): string {
  if (!answer) {
    return `Question not answered: ${question.text}`;
  }

  if (question.type === 'boolean' && answer.value === false) {
    return `Negative response indicates gap: ${question.text}`;
  }

  if (score < 30) {
    return `Significant gap identified (score: ${score}/100): ${question.text}`;
  }

  if (score < 70) {
    return `Partial compliance (score: ${score}/100): ${question.text}`;
  }

  return `Improvement opportunity (score: ${score}/100): ${question.text}`;
}
```

---

## Recommendation Generation

### Mapping Table Structure

Located in `src/data/recommendations/gap-to-recommendation-mapping.ts`:

```typescript
interface RecommendationTemplate {
  id: string;
  // Matching criteria
  applies_to_question_codes?: string[]; // e.g., ['GOV-001', 'GOV-002']
  applies_to_pillar?: QuestionPillar;
  applies_to_severity?: GapSeverity[];
  applies_to_jurisdictions?: Jurisdiction[]; // Jurisdiction-specific recs

  // Recommendation content
  title: string;
  title_arabic?: string;
  description: string;
  description_arabic?: string;
  why_it_matters: string;
  why_it_matters_arabic?: string;

  // Effort/impact
  effort: 'low' | 'medium' | 'high'; // Implementation effort
  impact: 'low' | 'medium' | 'high'; // Business impact

  // Actions
  actions: string[]; // Step-by-step actions
  actions_arabic?: string[];
}
```

### Recommendation Generation Algorithm

1. For each gap, find matching recommendation templates
2. Match by: question_code (most specific) â†’ pillar + severity â†’ pillar only
3. Filter by jurisdiction if applicable
4. Return top 1-3 recommendations per gap
5. Deduplicate across gaps (same recommendation may apply to multiple gaps)
6. Sort final list by: severity DESC, impact DESC, effort ASC

---

## Question Bank Enhancements (Backward-Compatible)

Add optional metadata fields to `Question` interface:

```typescript
interface Question {
  // Existing fields...

  // NEW: Scoring metadata (optional, backward-compatible)
  criticality?: 'critical' | 'normal'; // Default: 'normal'
  scoring_rules?: {
    // For single_choice questions
    option_scores?: Record<string, number>; // option.value â†’ score (0-100)

    // For number questions
    min?: number;
    target?: number;
    max?: number;

    // For date questions
    max_age_months?: number;
  };
}
```

Update question bank files to include scoring metadata for key questions. Example:

```typescript
// governance.ts
{
  id: 'GOV-001-uuid',
  code: 'GOV-001',
  text: 'Does your company have a formal board of directors?',
  type: 'boolean',
  weight: 8,
  criticality: 'critical', // NEW
  // ... rest of fields
}
```

---

## Free vs Paid Boundary Specification

### Free Tier (Current)
- âœ… Complete questionnaire
- âœ… View assessment results (scores, gaps, recommendations)
- âœ… Export results as PDF (basic)
- âœ… Methodology explanation

### Paid Tier (Future - Step 4+)
- ğŸ”’ **Disclosure Generator**: AI-powered narrative generation using:
  - Company profile data
  - Assessment results
  - Jurisdiction-specific templates
  - Regulatory citation engine
- ğŸ”’ Advanced analytics dashboard
- ğŸ”’ Year-over-year comparison
- ğŸ”’ Peer benchmarking

### UI Copy (Exact Strings)

**Free Compliance Check**:
```
Title: "Free Compliance Assessment"
Description: "Complete our questionnaire to receive instant compliance scores, gap analysis, and actionable recommendations."
```

**Results Page Header**:
```
Title: "Your Compliance Assessment Results"
Subtitle: "Based on {question_count} questions across {pillar_count} pillars"
Disclaimer: "This assessment provides educational insights only and does not constitute legal or regulatory advice. Consult qualified professionals for compliance guidance."
```

**Locked Disclosure Section**:
```
Title: "Generate Disclosure Report"
Lock Icon: ğŸ”’
Message: "Upgrade to Pro to generate jurisdiction-compliant disclosure narratives based on your assessment results."
Button: "Upgrade to Pro"
Features List:
â€¢ AI-powered disclosure narrative generation
â€¢ Jurisdiction-specific templates (UAE, KSA, Qatar)
â€¢ Regulatory citation engine
â€¢ Export to Word/PDF
â€¢ Year-over-year tracking
```

**Methodology Panel**:
```
Title: "How We Calculate Your Score"
Content: "Your compliance score is calculated using a transparent, deterministic methodology:

1. Question Weighting: Each question has a weight (1-10) based on regulatory importance.
2. Answer Scoring: Answers are scored 0-100 based on best practices for each question type.
3. Pillar Scores: Weighted average of questions within each pillar (Governance, ESG, Risk & Controls, Transparency).
4. Overall Score: Weighted average across all pillars (Governance 30%, ESG 25%, Risk 25%, Transparency 20%).

Gap Severity: Determined by question weight, answer quality, and criticality flags.
Recommendations: Matched from a curated database based on your specific gaps."
```

---

## DB Schema (Existing - No Migration Needed)

The `assessment_results` table already exists with the correct schema:

```sql
CREATE TABLE assessment_results (
  id uuid PRIMARY KEY,
  report_id uuid REFERENCES reports(id),
  questionnaire_response_id uuid REFERENCES questionnaire_responses(id),
  overall_score numeric(5,2) CHECK (overall_score >= 0 AND overall_score <= 100),
  pillar_scores jsonb, -- Array of {pillar, score, question_count, answered_count}
  gaps jsonb, -- Array of Gap objects
  gap_count integer,
  critical_gap_count integer,
  recommendations jsonb, -- Array of Recommendation objects
  explanation jsonb, -- Methodology explanation + scoring breakdown
  assessed_at timestamptz,
  created_at timestamptz,
  updated_at timestamptz
);
```

RLS policies already enforce FREE tier access (all authenticated users can view/create their company's assessments).

---

## Implementation Tasks

### Task 2: Scoring Module
**File**: `src/lib/scoring/compute-scores.ts`
- Implement answer type-specific scoring functions
- Compute per-pillar scores with weighted normalization
- Compute overall score
- Handle conditional questions (exclude if not shown)
- Handle unanswered questions (score = 0)
- Export `computeScores(template, responses, companyProfile)`

### Task 3: Gap Detection Module
**File**: `src/lib/gaps/detect-gaps.ts`
- Implement severity determination logic
- Generate rationale strings
- Derive required_action from question type
- Extract evidence_needed from question metadata
- Export `detectGaps(template, responses, scores)`

### Task 4: Recommendation Generation
**Files**:
- `src/data/recommendations/gap-to-recommendation-mapping.ts` - Mapping table
- `src/lib/recommendations/generate-recommendations.ts` - Matching logic
- Create 10-15 recommendation templates covering common gaps
- Implement jurisdiction-aware filtering
- Export `generateRecommendations(gaps, companyProfile)`

### Task 5: DB Persistence
**File**: `src/hooks/use-assessment-results.ts`
- `useAssessmentResult(reportId)` - Fetch
- `useCreateAssessment()` - Create
- `useUpdateAssessment()` - Update
- React Query with cache invalidation

### Task 6: UI Integration
**New Route**: `/compliance/results/:reportId`
**Components**:
- `src/pages/ComplianceResults.tsx` - Main page
- `src/components/assessment/ScoreCard.tsx` - Score display
- `src/components/assessment/GapsList.tsx` - Gaps table
- `src/components/assessment/RecommendationsList.tsx` - Recommendations
- `src/components/assessment/MethodologyPanel.tsx` - Explanation
- `src/components/assessment/UpgradePrompt.tsx` - Paid tier CTA

Add "View Results" button to Questionnaire page when completion > 0%.

### Task 7: Entitlements Spec
**File**: `ENTITLEMENTS_SPEC.md`
- Document free vs paid features
- UI copy strings
- Legal disclaimers
- Upgrade flow description

### Task 8: Testing
**Files**:
- `src/lib/scoring/compute-scores.test.ts` - Unit tests for scoring
- `src/lib/gaps/detect-gaps.test.ts` - Unit tests for gap severity
- `src/test/assessment.acceptance.test.ts` - E2E tests with seeded data
- Verify deterministic outputs (same inputs â†’ same outputs)
- Test UAE listed vs KSA non-listed scenarios

### Task 9: Completion Doc
**File**: `STEP3_COMPLETION.md`
- Summary of files changed
- Scoring methodology explanation
- Gap derivation logic
- Free/paid boundary copy
- Verification commands

---

## Acceptance Criteria

âœ… **Scoring works correctly**:
- Per-pillar scores (0-100) computed for all 4 pillars
- Overall score (0-100) computed with correct weighting
- Unanswered questions handled (score = 0)
- Conditional questions excluded if not shown
- All answer types scored per specification

âœ… **Gap detection is deterministic**:
- Severity (critical/high/medium/low) assigned consistently
- Same inputs always produce same gaps
- Rationale strings generated automatically
- Required actions derived from question context

âœ… **Recommendations are actionable**:
- 1-3 recommendations per gap
- Effort/impact estimates provided
- Jurisdiction-aware where relevant
- "Why it matters" explanations included

âœ… **Results persist to DB**:
- AssessmentResult saved to `assessment_results` table
- React Query hooks work (fetch/create/update)
- RLS policies enforced (free tier access)

âœ… **UI displays results**:
- New route `/compliance/results/:reportId` accessible
- Score cards show overall + pillar scores
- Gaps list with severity indicators
- Recommendations list with actions
- Methodology panel explains scoring
- Locked disclosure section with upgrade CTA

âœ… **Free/paid boundary clear**:
- Assessment results fully accessible (FREE)
- Disclosure generator locked with clear messaging
- Upgrade button visible with feature list
- Disclaimers present (not legal advice)

âœ… **Tests pass**:
- `npm test` succeeds (all unit + acceptance tests)
- `npm run build` succeeds
- Deterministic outputs verified
- UAE listed vs KSA non-listed test cases

---

## Assumptions & Design Decisions

1. **Criticality Metadata**: Add optional `criticality` field to question bank without breaking Step 2. Default to 'normal' if not specified.

2. **Option Scores**: For single/multi choice questions, if `scoring_rules.option_scores` not defined, use heuristic: first option = 100, last option = 0, interpolate linearly.

3. **Pillar Weights**: Fixed at Governance 30%, ESG 25%, Risk 25%, Transparency 20%. Make configurable in future if needed.

4. **Recommendation Limit**: Return top 10 recommendations max to avoid overwhelming users. Prioritize by severity â†’ impact â†’ effort.

5. **Text Question Scoring**: Simple presence check (100 if non-empty, 0 if empty). Future: add sentiment/keyword analysis for nuance.

6. **Date Question Scoring**: Recency-based. Default `max_age_months = 12` if not specified.

7. **Explanation Object**: Include scoring breakdown (question-by-question) for full transparency. Users can drill down into how each question contributed.

8. **Gap Threshold**: Only create gaps for questions scoring < 70. Don't overwhelm users with minor issues.

9. **Jurisdiction-Specific Recommendations**: Only a subset of recommendations are jurisdiction-specific (e.g., "Comply with UAE Corporate Governance Code"). Most are universal.

10. **Determinism Guarantee**: No external API calls, no randomness, no AI inference. All logic is pure functions with explicit rules.

---

**Next Step**: Begin Task 2 - Implement scoring module in `src/lib/scoring/compute-scores.ts`
